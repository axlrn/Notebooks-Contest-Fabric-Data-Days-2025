{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b376ad5",
   "metadata": {},
   "source": [
    "# Capítulo 5 — Enriquecimento com UN-Habitat Urban Data Portal\n",
    "\n",
    "Este notebook implementa as etapas de enriquecimento de dados descritas para o projeto **\"Cities of Tomorrow\"**:\n",
    "\n",
    "1. Acessar os dados do portal oficial da **UN-Habitat Urban Indicators Database**.\n",
    "2. Carregar os arquivos baixados (CSV/Excel) para os indicadores:\n",
    "   - Urban slums\n",
    "   - Access to water\n",
    "   - Access to sanitation\n",
    "   - Green area per capita\n",
    "   - PM2.5 (urban)\n",
    "   - Urban population growth\n",
    "   - Land consumption rate\n",
    "3. Padronizar país, ano e valores numéricos.\n",
    "4. Fazer **merge** com a base existente `wdi_merged.csv`.\n",
    "5. Salvar um arquivo enriquecido `wdi_merged_unhabitat.csv` para uso nos capítulos seguintes.\n",
    "\n",
    "> ⚠️ **Importante:**  \n",
    "> Este notebook assume que você já fez o download manual dos arquivos no portal da UN‑Habitat e os salvou com os nomes indicados nas variáveis de caminho.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72884a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CAPÍTULO 5 — ENRIQUECIMENTO COM UN-HABITAT URBAN DATA PORTAL\n",
    "# ============================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 1) Configuração de caminhos dos arquivos\n",
    "#    -> ajuste os caminhos conforme o seu Lakehouse/Fabric\n",
    "# ---------------------------------------------\n",
    "\n",
    "# Dataset principal (Kaggle + WDI já integrado nos capítulos anteriores)\n",
    "# Se já tiver um df_merged vindo de células anteriores, você pode pular este load.\n",
    "PATH_MAIN = \"/mnt/data/wdi_merged.csv\"\n",
    "\n",
    "# Arquivos baixados manualmente do UN-Habitat (ex.: Excel/CSV)\n",
    "# Dica: salve com nomes simples no Lakehouse/Files e ajuste aqui.\n",
    "PATH_SLUMS        = \"/mnt/data/unhabitat_slums.xlsx\"\n",
    "PATH_WATER        = \"/mnt/data/unhabitat_water_access.xlsx\"\n",
    "PATH_SANITATION   = \"/mnt/data/unhabitat_sanitation_access.xlsx\"\n",
    "PATH_GREEN        = \"/mnt/data/unhabitat_green_area_per_capita.xlsx\"\n",
    "PATH_PM25         = \"/mnt/data/unhabitat_pm25_urban.xlsx\"\n",
    "PATH_URB_POP      = \"/mnt/data/unhabitat_urban_population_midyear.xlsx\"\n",
    "PATH_LAND_CONS    = \"/mnt/data/unhabitat_land_consumption_rate.xlsx\"\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 2) Carregar dataset principal\n",
    "# ---------------------------------------------\n",
    "\n",
    "df_main = pd.read_csv(PATH_MAIN)\n",
    "\n",
    "print(\"Shape df_main (antes do UN-Habitat):\", df_main.shape)\n",
    "print(df_main.columns.tolist()[:20])\n",
    "\n",
    "# Vamos assumir que seu df_main tem algo como:\n",
    "# - 'Country Name' (nome do país em texto)\n",
    "# - 'Year'         (ano numérico)\n",
    "# Ajuste aqui se seus nomes forem outros:\n",
    "COUNTRY_COL_MAIN = \"Country Name\"\n",
    "YEAR_COL_MAIN    = \"Year\"\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 3) Funções auxiliares para padronizar país/ano\n",
    "# ---------------------------------------------\n",
    "\n",
    "def normalize_country_name(s):\n",
    "    \"\"\"Normaliza nomes de países para facilitar o merge por texto.\"\"\"\n",
    "    if pd.isna(s):\n",
    "        return np.nan\n",
    "    s = str(s).strip().upper()\n",
    "    # remove caracteres muito especiais\n",
    "    for ch in [\".\", \",\", \";\", \":\", \"'\", '\"', \"´\", \"`\"]:\n",
    "        s = s.replace(ch, \"\")\n",
    "    s = \" \".join(s.split())  # remove espaços duplicados\n",
    "    return s\n",
    "\n",
    "def prepare_unhabitat_generic(\n",
    "    path,\n",
    "    country_cols=(\"Country or Area\", \"Country Name\", \"COUNTRY\", \"Country\"),\n",
    "    year_cols=(\"Year\", \"Time\", \"TIME_PERIOD\"),\n",
    "    value_cols=(\"Value\", \"OBS_VALUE\", \"Indicator Value\"),\n",
    "    indicator_name=\"indicator\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Lê um arquivo UN-Habitat (Excel/CSV) e retorna um df padronizado:\n",
    "    ['country_key', 'Year', <indicator_name>]\n",
    "    Tentamos algumas opções de nomes de colunas típicas.\n",
    "    \"\"\"\n",
    "    # Detectar se é Excel ou CSV\n",
    "    if path.lower().endswith((\".xlsx\", \".xls\")):\n",
    "        df_raw = pd.read_excel(path)\n",
    "    else:\n",
    "        df_raw = pd.read_csv(path)\n",
    "    \n",
    "    df = df_raw.copy()\n",
    "\n",
    "    # 1) Detectar coluna de país\n",
    "    country_col = None\n",
    "    for c in country_cols:\n",
    "        if c in df.columns:\n",
    "            country_col = c\n",
    "            break\n",
    "    if country_col is None:\n",
    "        raise ValueError(f\"Não foi encontrada coluna de país em {path}. Colunas disponíveis: {df.columns.tolist()}\")\n",
    "\n",
    "    # 2) Detectar coluna de ano\n",
    "    year_col = None\n",
    "    for c in year_cols:\n",
    "        if c in df.columns:\n",
    "            year_col = c\n",
    "            break\n",
    "    if year_col is None:\n",
    "        raise ValueError(f\"Não foi encontrada coluna de ano em {path}. Colunas disponíveis: {df.columns.tolist()}\")\n",
    "\n",
    "    # 3) Detectar coluna de valor\n",
    "    value_col = None\n",
    "    for c in value_cols:\n",
    "        if c in df.columns:\n",
    "            value_col = c\n",
    "            break\n",
    "    if value_col is None:\n",
    "        # Se tiver exatamente uma coluna numérica principal, você pode\n",
    "        # tentar identificá-la automaticamente:\n",
    "        num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "        if len(num_cols) == 1:\n",
    "            value_col = num_cols[0]\n",
    "        else:\n",
    "            raise ValueError(f\"Não foi encontrada coluna de valor em {path}. Colunas disponíveis: {df.columns.tolist()}\")\n",
    "\n",
    "    # 4) Selecionar e renomear\n",
    "    df = df[[country_col, year_col, value_col]].copy()\n",
    "    df.columns = [\"Country_UNH\", \"Year\", indicator_name]\n",
    "\n",
    "    # 5) Limpeza básica\n",
    "    df[\"Year\"] = pd.to_numeric(df[\"Year\"], errors=\"coerce\")\n",
    "    df = df.dropna(subset=[\"Year\"])\n",
    "\n",
    "    # 6) Criar chave de país normalizada\n",
    "    df[\"country_key\"] = df[\"Country_UNH\"].apply(normalize_country_name)\n",
    "\n",
    "    # Remover duplicados (se houver vários registros por país-ano, pegamos a média)\n",
    "    df = (\n",
    "        df.groupby([\"country_key\", \"Year\"], as_index=False)[indicator_name]\n",
    "        .mean()\n",
    "    )\n",
    "\n",
    "    return df\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 4) Preparar cada indicador UN-Habitat\n",
    "#    (ajuste os 'indicator_name' se quiser renomear)\n",
    "# ---------------------------------------------\n",
    "\n",
    "df_slums = prepare_unhabitat_generic(\n",
    "    PATH_SLUMS,\n",
    "    indicator_name=\"uh_slums_pct\"\n",
    ")\n",
    "\n",
    "df_water = prepare_unhabitat_generic(\n",
    "    PATH_WATER,\n",
    "    indicator_name=\"uh_water_access_pct\"\n",
    ")\n",
    "\n",
    "df_san = prepare_unhabitat_generic(\n",
    "    PATH_SANITATION,\n",
    "    indicator_name=\"uh_sanitation_access_pct\"\n",
    ")\n",
    "\n",
    "df_green = prepare_unhabitat_generic(\n",
    "    PATH_GREEN,\n",
    "    indicator_name=\"uh_green_area_m2_per_capita\"\n",
    ")\n",
    "\n",
    "df_pm25 = prepare_unhabitat_generic(\n",
    "    PATH_PM25,\n",
    "    indicator_name=\"uh_pm25_ug_m3\"\n",
    ")\n",
    "\n",
    "df_urbpop = prepare_unhabitat_generic(\n",
    "    PATH_URB_POP,\n",
    "    indicator_name=\"uh_urban_population_thousands\"\n",
    ")\n",
    "\n",
    "df_land = prepare_unhabitat_generic(\n",
    "    PATH_LAND_CONS,\n",
    "    indicator_name=\"uh_land_consumption_rate\"\n",
    ")\n",
    "\n",
    "print(\"UN-Habitat: shapes individuais\")\n",
    "print(\"Slums       :\", df_slums.shape)\n",
    "print(\"Water       :\", df_water.shape)\n",
    "print(\"Sanitation  :\", df_san.shape)\n",
    "print(\"Green Area  :\", df_green.shape)\n",
    "print(\"PM2.5       :\", df_pm25.shape)\n",
    "print(\"Urban Pop   :\", df_urbpop.shape)\n",
    "print(\"Land Cons   :\", df_land.shape)\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 5) Criar chave de país no df_main\n",
    "# ---------------------------------------------\n",
    "\n",
    "df_main[\"country_key\"] = df_main[COUNTRY_COL_MAIN].apply(normalize_country_name)\n",
    "\n",
    "# Se o ano no df_main não estiver em uma coluna chamada \"Year\", ajuste YEAR_COL_MAIN acima\n",
    "if YEAR_COL_MAIN != \"Year\":\n",
    "    df_main = df_main.rename(columns={YEAR_COL_MAIN: \"Year\"})\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 6) Fazer merge incremental com todos os indicadores\n",
    "# ---------------------------------------------\n",
    "\n",
    "df_enriched = df_main.copy()\n",
    "\n",
    "for df_ind, ind_name in [\n",
    "    (df_slums, \"uh_slums_pct\"),\n",
    "    (df_water, \"uh_water_access_pct\"),\n",
    "    (df_san, \"uh_sanitation_access_pct\"),\n",
    "    (df_green, \"uh_green_area_m2_per_capita\"),\n",
    "    (df_pm25, \"uh_pm25_ug_m3\"),\n",
    "    (df_urbpop, \"uh_urban_population_thousands\"),\n",
    "    (df_land, \"uh_land_consumption_rate\"),\n",
    "]:\n",
    "    print(f\"Merging indicador: {ind_name}\")\n",
    "    df_enriched = df_enriched.merge(\n",
    "        df_ind[[\"country_key\", \"Year\", ind_name]],\n",
    "        on=[\"country_key\", \"Year\"],\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "print(\"Shape df_enriched (após UN-Habitat):\", df_enriched.shape)\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 7) Verificar cobertura dos novos indicadores\n",
    "# ---------------------------------------------\n",
    "\n",
    "novas_cols = [\n",
    "    \"uh_slums_pct\",\n",
    "    \"uh_water_access_pct\",\n",
    "    \"uh_sanitation_access_pct\",\n",
    "    \"uh_green_area_m2_per_capita\",\n",
    "    \"uh_pm25_ug_m3\",\n",
    "    \"uh_urban_population_thousands\",\n",
    "    \"uh_land_consumption_rate\",\n",
    "]\n",
    "\n",
    "print(df_enriched[novas_cols].describe(include=\"all\"))\n",
    "\n",
    "# Percentual de missing por novo indicador\n",
    "missing_summary = df_enriched[novas_cols].isna().mean().sort_values()\n",
    "print(\"\\nPercentual de missing por indicador UN-Habitat:\")\n",
    "print((missing_summary * 100).round(1).astype(str) + \"%\")\n",
    "\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 8) Salvar resultado enriquecido (para uso nos próximos capítulos)\n",
    "# ---------------------------------------------\n",
    "\n",
    "OUTPUT_PATH = \"/mnt/data/wdi_merged_unhabitat.csv\"\n",
    "df_enriched.to_csv(OUTPUT_PATH, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(f\"\\nArquivo salvo em: {OUTPUT_PATH}\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}